{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib ## model persistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkloc = '/rep/'\n",
    "reploc = pkloc\n",
    "loc = '/data1/SO_predict_DATA/'\n",
    "db_name = 'Processed.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean_train (title text NOT NULL,body text NOT NULL, code text, tags text, words_pre integer, words_post integer, is_code integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_report(msg,di):               # create csv file with header\n",
    "    rep = \"\\n\"+msg+\" :\\n\\t\"+str(di)\n",
    "    fp = open(reploc+'report.txt','a')\n",
    "    fp.write(rep)\n",
    "    fp.close()\n",
    "\n",
    "def save_report_csv(msg,di):               # create csv file with header\n",
    "    cn = pd.read_csv(reploc+'report.csv')\n",
    "    for k,v in di.items():\n",
    "        cn.loc[msg,k] = v\n",
    "    #cn.to_csv(reploc+'report.csv')\n",
    "    return cn\n",
    "    \n",
    "\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(loc+db_file)\n",
    "        return conn\n",
    "    except sqlite3.Error as e:\n",
    "        print(e)\n",
    " \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = create_connection(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_rm = list( pd.read_csv('tag_to_remove.csv')['Tags'] )\n",
    "t = [str(i) for i in tag_rm]\n",
    "li_string = \"('\"+ \"','\".join(t) +\"')\" # li_string = '(\"'+ '\",\"'.join(t) +'\")' #  ' vs \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if con is not None:\n",
    "    tag_data = pd.read_sql('SELECT tags FROM clean_train WHERE tags NOT IN '+li_string,con)\n",
    "else :\n",
    "    print('Conn error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  tags\n",
      "0          c# silverlight data-binding\n",
      "1  c# silverlight data-binding columns\n",
      "2                             jsp jstl\n",
      "3                            java jdbc\n",
      "4        facebook api facebook-php-sdk\n",
      "Shape (4125991, 1)\n"
     ]
    }
   ],
   "source": [
    "print(tag_data.head())\n",
    "print('Shape',tag_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if con is not None:\n",
    "    t_data = pd.read_sql('SELECT Title FROM clean_train WHERE Tags NOT IN '+li_string,con)\n",
    "else :\n",
    "    print('Conn error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title\n",
      "0                    dynam datagrid bind silverlight\n",
      "1                    dynam datagrid bind silverlight\n",
      "2  java.lang.noclassdeffounderror javax servlet j...\n",
      "3  java.sql.sqlexcept microsoft odbc driver manag...\n",
      "4                   better way updat feed fb php sdk\n",
      "Shape (4125991, 1)\n"
     ]
    }
   ],
   "source": [
    "print(t_data.head())\n",
    "print('Shape',t_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess title Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_data = t_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----- Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if con is not None:\n",
    "    b_data = pd.read_sql('SELECT Body FROM data  WHERE Tags NOT IN '+li_string,con)\n",
    "else :\n",
    "    print('Conn error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b_data[:5])\n",
    "print('Shape',b_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_data = b_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------- title+body = ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4125991, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_data = pd.DataFrame()\n",
    "title_data['ques'] = t_data.Title + b_data.Body\n",
    "title_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tag = CountVectorizer(tokenizer = lambda x: x.split(), binary='true',min_df = 25)  # min_df - document frequency strictly lower than the given threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lab_y = vectorizer_tag.fit_transform(tag_data.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary='true', decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=25,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function <lambda> at 0x7fb4a7e4d510>, vocabulary=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(tag_data.Tags,pkloc+'tag_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points : 4125991\n",
      "Number of unique tags : 17681\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points :\", multi_lab_y.shape[0])\n",
    "print(\"Number of unique tags :\", multi_lab_y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer_tag.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## choose first n tags (desc order of count)\n",
    "\n",
    "def tags_to_choose(n):\n",
    "    t = multilabel_y.sum(axis=0).tolist()[0]\n",
    "    sorted_tags_i = sorted(range(len(t)), key=lambda i: t[i], reverse=True)\n",
    "    multilabel_yn = multilabel_y[:,sorted_tags_i[:n]]\n",
    "    return multilabel_yn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4.2 Split the data into test and train (80:20) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4125991 3300792\n"
     ]
    }
   ],
   "source": [
    "tot_size = title_data.shape[0]\n",
    "train_size = int(tot_size * 0.8)\n",
    "print(tot_size,train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=title_data.head(train_size)\n",
    "x_test=title_data.tail(tot_size - train_size)\n",
    "\n",
    "y_train = multi_lab_y[0:train_size,:]\n",
    "y_test = multi_lab_y[train_size:tot_size,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(y_test,pkloc+'y_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @ Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.00009, max_features=200000, smooth_idf=True, norm=\"l2\", \\\n",
    "                             tokenizer = lambda x: x.split(), sublinear_tf=False, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:02:18.831460\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "x_train_multilabel = vectorizer.fit_transform(x_train.title)     ## replace column name appropiately\n",
    "x_test_multilabel = vectorizer.transform(x_test.title)\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train data X: (3300792, 7731) Y : (3300792, 17681)\n",
      "Dimensions of test data X: (825199, 7731) Y: (825199, 17681)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of train data X:\",x_train_multilabel.shape, \"Y :\",y_train.shape)\n",
    "print(\"Dimensions of test data X:\",x_test_multilabel.shape,\"Y:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(x_test_multilabel,pkloc+'body_xtest_multilabel.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDC with OnevsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/externals/loky/backend/queues.py\", line 150, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/externals/loky/backend/reduction.py\", line 243, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/externals/loky/backend/reduction.py\", line 236, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py\", line 284, in dump\n    return Pickler.dump(self, obj)\n  File \"/usr/lib/python3.5/pickle.py\", line 408, in dump\n    self.save(obj)\n  File \"/usr/lib/python3.5/pickle.py\", line 520, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/usr/lib/python3.5/pickle.py\", line 623, in save_reduce\n    save(state)\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.5/pickle.py\", line 810, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/usr/lib/python3.5/pickle.py\", line 836, in _batch_setitems\n    save(v)\n  File \"/usr/lib/python3.5/pickle.py\", line 520, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/usr/lib/python3.5/pickle.py\", line 623, in save_reduce\n    save(state)\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.5/pickle.py\", line 810, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/usr/lib/python3.5/pickle.py\", line 841, in _batch_setitems\n    save(v)\n  File \"/usr/lib/python3.5/pickle.py\", line 520, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/usr/lib/python3.5/pickle.py\", line 623, in save_reduce\n    save(state)\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.5/pickle.py\", line 810, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/usr/lib/python3.5/pickle.py\", line 836, in _batch_setitems\n    save(v)\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.5/pickle.py\", line 770, in save_list\n    self._batch_appends(obj)\n  File \"/usr/lib/python3.5/pickle.py\", line 797, in _batch_appends\n    save(tmp[0])\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.5/pickle.py\", line 725, in save_tuple\n    save(element)\n  File \"/usr/lib/python3.5/pickle.py\", line 475, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.5/pickle.py\", line 725, in save_tuple\n    save(element)\n  File \"/usr/lib/python3.5/pickle.py\", line 481, in save\n    rv = reduce(obj)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_memmapping_reducer.py\", line 339, in __call__\n    for dumped_filename in dump(a, filename):\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py\", line 502, in dump\n    NumpyPickler(f, protocol=protocol).dump(value)\n  File \"/usr/lib/python3.5/pickle.py\", line 408, in dump\n    self.save(obj)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py\", line 289, in save\n    wrapper.write_array(obj, self)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py\", line 104, in write_array\n    pickler.file_handle.write(chunk.tostring('C'))\nOSError: [Errno 28] No space left on device\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-210f1280aca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hinge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_multilabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_multilabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;34m\"not %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 self.label_binarizer_.classes_[i]])\n\u001b[0;32m--> 215\u001b[0;31m             for i, column in enumerate(columns))\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='hinge', alpha=0.00001, penalty='l1'), n_jobs=-1)\n",
    "classifier.fit(x_train_multilabel, y_train)\n",
    "predictions = classifier.predict(x_test_multilabel)\n",
    "\n",
    "time_t = datetime.now() - start\n",
    "#print(\"macro f1 score :\",metrics.f1_score(y_test, predictions, average = 'macro'))\n",
    "#print(\"micro f1 scoore :\",metrics.f1_score(y_test, predictions, average = 'micro'))\n",
    "#print(\"hamming loss :\",metrics.hamming_loss(y_test,predictions))\n",
    "#print(\"Precision recall report :\\n\",metrics.classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'micro_f1_score': 0.42031202202508416, 'Time_taken': '0:00:06.359023', 'accuracy': 0.12780040733197556}\n"
     ]
    }
   ],
   "source": [
    "rep_di = dict()\n",
    "rep_di[\"Time_taken\"] = str(time_t)\n",
    "rep_di[\"accuracy\"] = metrics.accuracy_score(y_test,predictions)\n",
    "rep_di[\"micro_f1_score\"] = metrics.f1_score(y_test, predictions, average = 'micro')\n",
    "print(str(rep_di))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_report(\"SGDC with OnevsRest - hinge\",rep_di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(classifier,pkloc+'title_sgdc_hinge.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic with OnevsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier2 = OneVsRestClassifier(LogisticRegression(penalty='l1'), n_jobs=-1)\n",
    "classifier2.fit(x_train_multilabel, y_train)\n",
    "predictions2 = classifier2.predict(x_test_multilabel)\n",
    "\n",
    "time_t = datetime.now() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rep_di = dict()\n",
    "rep_di[\"Time_taken\"] = str(time_t)\n",
    "rep_di[\"accuracy\"] = metrics.accuracy_score(y_test,predictions2)\n",
    "rep_di[\"micro_f1_scoore\"] = metrics.f1_score(y_test, predictions2, average = 'micro')\n",
    "print(str(rep_di))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_report(\"Logistic with OnevsRest\",rep_di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(classifier2,pkloc+'body_logistic.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA  -- TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train3 =y_train.todense()\n",
    "y_test3 = y_test.todense()\n",
    "\n",
    "print type(y_train)\n",
    "print type(x_train_multilabel.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "#classifier3 = OneVsRestClassifier(LDA())\n",
    "#classifier3.fit(x_train_multilabel.todense(), y_train)\n",
    "#predictions3 = classifier3.predict(x_test_multilabel)\n",
    "\n",
    "#print(\"Time taken to run this cell :\", datetime.now() - start)\n",
    "#print(\"accuracy :\",metrics.accuracy_score(y_test,predictions3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier4 = OneVsRestClassifier(LinearSVC(), n_jobs=-1)\n",
    "classifier4.fit(x_train_multilabel, y_train)\n",
    "predictions4 = classifier4.predict(x_test_multilabel)\n",
    "\n",
    "time_t = datetime.now() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rep_di = dict()\n",
    "rep_di[\"Time_taken\"] = str(time_t)\n",
    "rep_di[\"accuracy\"] = metrics.accuracy_score(y_test,predictions4)\n",
    "rep_di[\"micro_f1_scoore\"] = metrics.f1_score(y_test, predictions4, average = 'micro')\n",
    "print(str(rep_di))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_report(\"SVC\",rep_di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(classifier4,pkloc+'body_svc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLkNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "classifier_k = MLkNN(k=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_k.fit(x_train_multilabel, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions5 = classifier_k.predict(x_test_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_di = dict()\n",
    "rep_di[\"Time_taken\"] = str(time_t)\n",
    "rep_di[\"accuracy\"] = metrics.accuracy_score(y_test,predictions5)\n",
    "rep_di[\"micro_f1_scoore\"] = metrics.f1_score(y_test, predictions5, average = 'micro')\n",
    "print(str(rep_di))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_report(\"MLkNN 21\",rep_di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = vectorizer_tag.inverse_transform(y_test)\n",
    "actual = [' '.join(i) for i in actual]\n",
    "actual = pd.Series(actual,name=\"Actual\")\n",
    "#actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = vectorizer_tag.inverse_transform(predictions)\n",
    "preds = [' '.join(i) for i in preds]\n",
    "preds = pd.Series(preds,name=\"Pred_by_ques\")\n",
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resul_df = pd.concat([actual,preds],axis=1)\n",
    "#resul_df.to_csv(\"01_resul_rep.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rr = pd.read_csv('01_resul_rep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rr.append?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr['pred_by_ques']=preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.to_csv(\"01_rep_mindf_03.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.read_csv('01_rep_mindf_03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_x_test_multilabel = joblib.load('/data/title_xtest_multilabel.pkl')\n",
    "\n",
    "title_sgc = joblib.load('/data/title_sgdc.pkl')\n",
    "\n",
    "pred_title = title_sgc.predict(title_x_test_multilabel)\n",
    "\n",
    "print(\"From title accuracy :\",metrics.accuracy_score(y_test,pred_title))\n",
    "print(\"From title micro f1 scoore :\",metrics.f1_score(y_test, pred_title, average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_x_test_multilabel = joblib.load('/data/body_xtest_multilabel.pkl')\n",
    "\n",
    "body_sgc = joblib.load('/data/body_sgdc.pkl')\n",
    "\n",
    "pred_body = body_sgc.predict(body_x_test_multilabel)\n",
    "\n",
    "print(\"From body accuracy :\",metrics.accuracy_score(y_test,pred_body))\n",
    "print(\"From body micro f1 scoore :\",metrics.f1_score(y_test, pred_body, average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_or = pred_title.todense() | pred_body.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"From OR accuracy :\",metrics.accuracy_score(y_test,p_or))\n",
    "print(\"From OR micro f1 scoore :\",metrics.f1_score(y_test, p_or, average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = vectorizer_tag.inverse_transform(p_or)\n",
    "preds = [' '.join(i) for i in preds]\n",
    "preds = pd.Series(preds,name=\"Pred_by_OR\")\n",
    "r['pred_by_OR'] = preds\n",
    "r.to_csv(\"01_rep_mindf_03.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.read_csv('01_rep_mindf_03.csv')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
